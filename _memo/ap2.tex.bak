\part{Apprentissage}
\pagebreak

\chapter{Approche d'apprentissage par la logique}
Une approche simple concernant l'apprentissage de problèmes dont le domaine de sortie est boolean
serait de passer par la logique classique pour pouvoir simplifier la compréhension du problème.\\
\pagebreak
\section{Espace de Version}
Pour un problème suivant:

$\begin{tabular}{cccc|c}
\hline
A & B & C & D & accaptable? \\
\hline
1 & 1 & 1 & 0 & oui\\
1 & 1 & 0 & 1 & oui\\
0 & 1 & 1 & 1 & non\\
\hline
\end{tabular}$

\ \\
D'où il suffirait d'une fonction donnant dans le domaine Boolean, associer un algorithme de classification simple:\\
\ \\
\vspace{1cm}
\scalebox{0.7}{
\begin{tikzpicture}
  \begin{axis} [
      xlabel     = X, % label x axis
      ylabel     = Y, % label y axis
      axis lines = left, %set the position of the axes
      clip       = false, 
      xmin       = 0,
      ymin       = 0,
    ]
    \addplot [color=black] coordinates { (0,0)(5,5) };
    \addplot [only marks, mark=*, color=blue] coordinates {(1,4)(3,3.5) };
    \addplot [only marks, mark=*, color=red] coordinates {(4,2) };
  \end{axis}
\end{tikzpicture}
}

\vspace{1cm}

Ayant comme points de couleurs $\crouge{Rouge}$ les points donnant la valeur de vérité False et les points de couleurs $\cblue{Blue}$ les point donnant la valeur de vérité True.\\
Mais ce ne serait pas donner un gros mode de résolution à un problème qui peut être simplifié?\\
\\
Pour les cas suivants:
\begin{description}
\item[-] Faciliter la compréhension du problème
\item[-] Comprendre pourquoi une décision donné pour une entrée
\end{description}
\pagebreak

\subsection{convergence des données}

Dans le tableau d'acceptation on peut transformé la règle 3 en son dual via la Lois de De Morgan:\\

\begin{multicols}{2}
[Et via un treillis de donnée pour chaque entré positif on peut compter le nombre d'occurrence de motif en faveur de l'acceptation de la ligne:]
\scalebox{0.3}{
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.8cm,
                    semithick]
  \tikzstyle{every state}=[fill=white,draw=none,text=black]

  \node[state]         (Z)                    {$\{\}$};
  \node[state]         (B) [below left  of=Z] {$B$};
  \node[state]         (A) [left  of=B]       {$A$};
  \node[state]         (C) [below right of=Z] {$C$};
  \node[state]         (D) [right of=C]       {$D$};
  \node[state]		   (AC) [below  of=A]     {$AC$};
  \node[state]		   (AB) [left of=AC]      {$AB$};
  \node[state]		   (AD) [right of=AC]     {$AD$};
  \node[state]         (BC) [right of=AD]     {$BC$};
  \node[state]		   (BD) [right of=BC]	  {$BD$};
  \node[state]		   (CD) [right of=BD] 	  {$CD$};
  \node[state]		   (ABD) [below of=AD]    {$ABD$};
  \node[state] 		   (ABC) [left of=ABD]    {$ABC$};
  \node[state]		   (ACD) [right of=ABD]   {$ACD$};
  \node[state]		   (BCD) [right of=ACD]   {$BCD$};
  \node[state]	       (ABCD) [below of=ABD]  {$ABCD$};
  

  \path (Z) edge              node {} (A)
            edge              node {} (B)
            edge			  node {} (C)
            edge  			  node {} (D)
        (A) edge			  node {} (AB)
        	edge			  node {} (AC)
        	edge			  node {} (AD)
        (B) edge			  node {} (AB)
        	edge			  node {} (BC)
        	edge 			  node {} (BD)
        (C) edge 			  node {} (AC)
        	edge			  node {} (BC)
        	edge 			  node {} (CD)
        (D) edge 			  node {} (AD)
        	edge 			  node {} (BD)
        	edge 			  node {} (CD)
        (AB) edge 			  node {} (ABC)
        	edge 			  node {} (ABD)
        (AC) edge			  node {} (ABC)
        	edge 			  node {} (ACD)
        (AD) edge 			  node {} (ABD)
        	edge			  node {} (ACD)
        (BC) edge			  node {} (ABC)
        	edge  			  node {} (BCD)
        (BD) edge			  node {} (ABD)
        	edge 			  node {} (BCD)
        (CD) edge 			  node {} (ACD)
        	edge			  node {} (BCD)
        (ABC) edge 			  node {} (ABCD)
        (ACD) edge 			  node {} (ABCD)
        (ABD) edge 			  node {} (ABCD)
        (BCD) edge 			  node {} (ABCD);
\end{tikzpicture}
}
$\begin{tabular}{cccc|c}
\hline
A & B & C & D & accaptable? \\
\hline
1 & 1 & 1 & 0 & oui\\
1 & 1 & 0 & 1 & oui\\
1 & 0 & 0 & 0 & oui\\
\hline
\end{tabular}$
\end{multicols}
\ \\

\begin{multicols}{2}
[]
\scalebox{0.4}{
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.8cm,
                    semithick]
  \tikzstyle{every state}=[fill=white,draw=none,text=black]

  \node[state]         (Z)                    {$\{\}$};
  \node[state]         (B) [below  of=Z]      {$B$};
  \node[state]         (A) [left  of=B]       {$A$};
  \node[state]         (C) [right of=B]       {$C$};
  \node[state]		   (AB) [below of=A]      {$AB$};
  \node[state]		   (AC) [right of=AB]     {$AC$};
  \node[state]         (BC) [right of=AC]     {$BC$};
  \node[state] 		   (ABC) [below of=AC]    {$ABC$};
  

  \path (Z) edge              node {} (A)
            edge              node {} (B)
            edge			  node {} (C)
        (A) edge			  node {} (AB)
        	edge			  node {} (AC)
        (B) edge			  node {} (AB)
        	edge			  node {} (BC)
        (C) edge 			  node {} (AC)
        	edge			  node {} (BC)
        (AB) edge 			  node {} (ABC)
        (AC) edge			  node {} (ABC)
        (BC) edge			  node {} (ABC);
\end{tikzpicture}
}
$\begin{tabular}{cccc|c}
\hline
A & B & C & D & accaptable? \\
\hline
\crouge{1} & \crouge{1} & \crouge{1} & \crouge{0} & \crouge{oui}\\
1 & 1 & 0 & 1 & oui\\
1 & 0 & 0 & 0 & oui\\
\hline
\end{tabular}$
\end{multicols}
\pagebreak

\begin{multicols}{2}
[]
\scalebox{0.4}{
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.8cm,
                    semithick]
  \tikzstyle{every state}=[fill=white,draw=none,text=black]

  \node[state]         (Z)                    {$\{\}$};
  \node[state]         (B) [below  of=Z]      {$B$};
  \node[state]         (A) [left  of=B]       {$A$};
  \node[state]		   (AB) [below of=A]      {$AB$};
  

  \path (Z) edge              node {} (A)
            edge              node {} (B)
        (A) edge			  node {} (AB)
        (B) edge			  node {} (AB);
\end{tikzpicture}
}
$\begin{tabular}{cccc|c}
\hline
A & B & C & D & accaptable? \\
\hline
1 & 1 & 1 & 0 & oui\\
\crouge{1} & \crouge{1} & \crouge{0} & \crouge{1} & \crouge{oui}\\
1 & 0 & 0 & 0 & oui\\
\hline
\end{tabular}$
\end{multicols}

\begin{multicols}{2}
[]
\scalebox{0.4}{
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.8cm,
                    semithick]
  \tikzstyle{every state}=[fill=white,draw=none,text=black]

  \node[state]         (Z)                    {$\{\}$};
  \node[state]         (A) [left  of=B]       {$A$};
  

  \path (Z) edge              node {} (A);
\end{tikzpicture}
}
$\begin{tabular}{cccc|c}
\hline
A & B & C & D & accaptable? \\
\hline
1 & 1 & 1 & 0 & oui\\
1 & 1 & 0 & 1 & oui\\
\crouge{1} & \crouge{0} & \crouge{0} & \crouge{0} & \crouge{oui}\\
\hline
\end{tabular}$
\end{multicols}

\ \\
Par itération et réduction du treillis on sait que $A$ et un attribut très discriminant, qui fait revenir le problème à seulement la valeur de $A$.\\

\pagebreak
\chapter{Apprentissage statistique}

Dans ce chapitre nous nous intéressons à des fonctions $h \in H$ à qui pour une liste $X$ à $d$ dimension de domaine réelle associe un label $y$ dans le domaine $[-1,+1]$. Un $x \in X$ peut être une couleur, un réelle, une chose négatif ou encore une mesure quelconque.
\pagebreak

\section{Classification binaire réalisable}

Chaque entrée $x \in X$ est tirée aléatoirement et indépendamment selon une distribution de probabilité $d$ qui est fixée mais inconnue de l'apprenant.
\\
Chaque sortie $y \in Y$ est calculé via la fonction cible $h* \in H$ qui est inconnue de l'apprenant.

\subsection{Erreur de généralisation et d'entrainement}

La performance d'une hypothèse $h \in H$ est calculé par le nombre d'erreurs que la fonction peut commettre en probabilité selon $d$:
\begin{description}
\item[] $l_d(h)$ = $P_{x~d}[h(x) \neg h*(x)]$
\end{description}

En pratique, l'apprenant n'a accès qu'a une petite partit nommé $S \in X$ (qui peut contenir des doublons) dont les éléments dont générés aléatoirement via $d$, Le risque empirique de $h$ par rapport à $S$ est donné par :
\begin{description}
\item[] $l_s(h)$ = $\frac{1}{|S|} |\{x \in S : h(x) \neg h*(x)\}|$
\end{description}
Le nombre d'erreur moyen que fait $h$ sur $S$\\

\subsection{Processus d'apprentissage}

Le processus d'apprentissage n'est pas si différent que dans la première partie du Memo:\\

Soit une distribution $d$, chaque requêtes vers $d$ va choisir un échantillons aléatoirement pour crée un ensemble $S$ qui va servir à faire apprendre $h$ lors de la phase d'apprentissage, tester lors de la phase de teste et retenir les erreur vies les fonction d'analyse.\\

\subsection{Incertitude de l'apprentissage}
\subsection{Modèle PAC réalisable}
\subsection{Classes d'hypothèses finies}
\subsection{Minimisation des erreurs empirique}
\pagebreak
\section{Classification binaire agnostique}
\subsection{Régression agnostique}


\pagebreak

